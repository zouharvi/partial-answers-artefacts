%
% File lfd1617.tex
%
%% Based on the style files for EACL-2017
%% Based on the style files for ACL-2016
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{eacl2017}
\usepackage{graphicx}
\usepackage{times}
\usepackage{url}
\usepackage[normalem]{ulem}
\usepackage{latexsym}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{rotating,multirow}
\usepackage[svgnames]{xcolor}
% \usepackage{natbib}
\usepackage{amssymb,fge}
\usepackage{mathtools}

\def\code#1{\texttt{#1}}

%%%% LEAVE THIS IN
\eaclfinalcopy

\newcommand\TODO[1]{\textcolor{red}{TODO: #1}}
\newcommand\TODOEDU[1]{\textcolor{DarkCyan}{TODO (Edu): #1}}
\newcommand\TODOV[1]{\textcolor{DarkRed}{TODO (Vilda): #1}}
\newcommand\bananas[2]{$#1\%$ {\hspace{-0.05cm}\tiny $(#2\%)$\hspace{-0.3cm}} }
\newcommand{\mysetminus}{\mathbin{\fgebackslash}}
\newcommand\prc[1]{$#1\%$}
\newcommand\prcB[2]{$#1\%$ {\small $#2\%$}}
\newcommand\defeq{\,\,\stackrel{\mathclap{def}}{=}\,\,}

\title{Fusion of Partial Answers as Artefacts for Multi-Output Classification}

\author{
    Vil√©m Zouhar \\ s5000076 \\
    \texttt{vilem.zouhar@gmail.com}
    \And
    Edu Vallejo Arguinzoniz \\ s5016894 \\
    \texttt{vallezoniz@gmail.com}
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
    Multi-output learning faces interesting challenges because of the delicate dependencies between predicted variables.
    These variables can also serve as ideal artefacts that can be fused into the model computation to improve the performance.
    We study the effect of this provision of extra information and examine its effect on the intermediate model computation.
    
    We find that for this specific case, multi-task learning is a more efficient solution that slightly outperforms having individual models.
    We demonstrate that
    (1) fusion of some of the variables helps the model (performance),
    (2) it is possible to predict when the model needs them (efficiency) and
    (3) the fusion effects are clearly visible in the computation (explainability).
\end{abstract}

\input{content.tex}

\section*{Acknowledgements}

For our experiments, we made use of the LSV computation cluster at Saarland University.

\bibliographystyle{eacl2017}
\bibliography{bibliography.bib}

\newpage

\appendix

\input{appendix.tex}

\end{document}